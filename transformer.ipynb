{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install -q --upgrade datasets transformers evaluate peft","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","id":"-AUz8eKzsDRU","outputId":"a1d53d1c-2f11-483f-d937-5a40698f090a","execution":{"iopub.status.busy":"2023-10-11T04:28:57.246655Z","iopub.execute_input":"2023-10-11T04:28:57.247008Z","iopub.status.idle":"2023-10-11T04:29:06.691390Z","shell.execute_reply.started":"2023-10-11T04:28:57.246978Z","shell.execute_reply":"2023-10-11T04:29:06.689798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from huggingface_hub import notebook_login\n# notebook_login()\n# # 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","metadata":{"execution":{"iopub.status.busy":"2023-10-11T04:29:06.694229Z","iopub.execute_input":"2023-10-11T04:29:06.694664Z","iopub.status.idle":"2023-10-11T04:29:06.699010Z","shell.execute_reply.started":"2023-10-11T04:29:06.694619Z","shell.execute_reply":"2023-10-11T04:29:06.698026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nimport os\n\n# from huggingface_hub import cached_download, hf_hub_url\n\nid2label = {0:\"background\", 1:\"wound\"}\nlabel2id = {v: k for k, v in id2label.items()}\nnum_labels = len(id2label)","metadata":{"execution":{"iopub.status.busy":"2023-10-11T04:29:06.700492Z","iopub.execute_input":"2023-10-11T04:29:06.701092Z","iopub.status.idle":"2023-10-11T04:29:06.712450Z","shell.execute_reply.started":"2023-10-11T04:29:06.701062Z","shell.execute_reply":"2023-10-11T04:29:06.711418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\n\nkeras.backend.set_image_data_format('channels_last')\n# %pip install graphviz\nimport os\nimport numpy as np\nimport pandas as pd\nfrom glob import glob\nimport tensorflow as tf\nimport graphviz\nimport keras\nimport datetime\nfrom torch import nn\nimport torch\n\n# Data\nfrom keras import backend as K\nfrom tqdm import tqdm\n\nprint(os.getcwd())\n\n# Data Viz\nimport matplotlib.pyplot as plt\nimport gc\n\nfrom sklearn.model_selection import train_test_split\n\n# Model\nfrom keras.models import Model\nfrom keras.layers import Layer\nfrom keras.layers import Conv2D\nfrom keras.layers import Dropout\nfrom keras.layers import UpSampling2D\nfrom keras.layers import concatenate\nfrom keras.layers import Add\nfrom keras.layers import Multiply\nfrom keras.layers import Input\nfrom keras.layers import MaxPool2D\nfrom keras.layers import BatchNormalization\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\n# Callbacks\nfrom keras.callbacks import Callback\nfrom keras.callbacks import EarlyStopping\nfrom keras.callbacks import ModelCheckpoint\n\n# %pip install -qU albumentations[imgaug]\n# %pip install -qU imgaug\n# import albumentations as A\nimport tensorflow_addons as tfa\n\n%pip install -qU tf_explain\nfrom tf_explain.core.grad_cam import GradCAM\n\nimport cv2\nfrom keras.metrics import MeanIoU","metadata":{"execution":{"iopub.status.busy":"2023-10-11T04:29:06.715724Z","iopub.execute_input":"2023-10-11T04:29:06.716270Z","iopub.status.idle":"2023-10-11T04:29:15.859631Z","shell.execute_reply.started":"2023-10-11T04:29:06.716236Z","shell.execute_reply":"2023-10-11T04:29:15.858141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df = pd.read_csv(\"/kaggle/input/wounds/description.csv\")\n# df[\"Path to files\"] = df[\"Path to files\"].apply(lambda x: os.path.join(dir,x).replace(\"\\\\\",\"/\"))\n# df.head()\n\n# i = df['Path to files'][0]\n# image = tf.keras.utils.load_img(os.path.join(i,'photo.jpg'))\n# input_arr = tf.keras.utils.img_to_array(image)\n# input_arr\n\n# img_shape = (1224, 816)\n\n# images = np.zeros((len(df), img_shape[0], img_shape[1], 3))\n# masks = np.zeros((len(df), img_shape[0], img_shape[1], 1))\n\n# for idx,i in tqdm(enumerate(df['Path to files'])):\n#   image = tf.keras.utils.load_img(os.path.join(i,'photo.jpg'), target_size=img_shape,  method=\"lanczos\")\n#   input_arr = tf.keras.utils.img_to_array(image) / 255.\n#   images[idx] = input_arr\n#   image = tf.keras.utils.load_img(os.path.join(i,'mask.png'), color_mode=\"grayscale\" , target_size=img_shape, method=\"lanczos\")\n#   input_arr = tf.keras.utils.img_to_array(image) / 255.\n#   masks[idx] = input_arr\n\n# os.path.join(dir,\"images.npy\")\n\n# with open(os.path.join(dir,\"images.npy\"), 'wb') as f:\n#   np.save(f,images)\n\n# with open(os.path.join(dir,\"masks.npy\"), 'wb') as f:\n#   np.save(f,masks)\n\n# masks = np.load(os.path.join(dir,\"masks.npy\"))\n# images = np.load(os.path.join(dir,\"images.npy\"))\n\n\n# images = np.load(\"/kaggle/input/wounds/images.npy\")\n# masks = np.load(\"/kaggle/input/wounds/masks.npy\")\n\n# train_idx, test_idx = train_test_split(range(len(df)), test_size=0.1, random_state=50)\n\n# train_dataset = tf.data.Dataset.from_tensor_slices((images[train_idx],masks[train_idx]))\n# test_dataset  = tf.data.Dataset.from_tensor_slices((images[test_idx],  masks[test_idx]))","metadata":{"id":"6mfZB3NVHIAm","outputId":"bcc9c6c2-1197-41fd-d9f4-6cd21604d474","execution":{"iopub.status.busy":"2023-10-11T04:29:15.863783Z","iopub.execute_input":"2023-10-11T04:29:15.864675Z","iopub.status.idle":"2023-10-11T04:29:15.872533Z","shell.execute_reply.started":"2023-10-11T04:29:15.864616Z","shell.execute_reply":"2023-10-11T04:29:15.871096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_shape = [128,128,3]\n# img_shape = [160,160,3]","metadata":{"execution":{"iopub.status.busy":"2023-10-11T04:29:15.874189Z","iopub.execute_input":"2023-10-11T04:29:15.875392Z","iopub.status.idle":"2023-10-11T04:29:15.891722Z","shell.execute_reply.started":"2023-10-11T04:29:15.875328Z","shell.execute_reply":"2023-10-11T04:29:15.890523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def brightness_contrast(image):\n#     image = tf.image.random_brightness(image, 0.3)\n#     image = tf.image.random_contrast(image, 0.7, 1.3)\n#     return image\n    \n# def rotate(image, mask):\n#     angle1 = tf.random.uniform(shape=[])*45\n#     image1 = tfa.image.rotate(image, np.pi/360*angle1)\n#     mask1  = tfa.image.rotate(mask, np.pi/360*angle1)\n    \n#     angle2 = tf.random.uniform(shape=[])*-45\n#     image2 = tfa.image.rotate(image, np.pi/360*angle2)\n#     mask2  = tfa.image.rotate(mask, np.pi/360*angle2)\n    \n# #     angle3 = tf.random.uniform(shape=[])*45\n# #     image3 = tfa.image.rotate(image, np.pi/360*angle3)\n# #     mask3  = tfa.image.rotate(mask, np.pi/360*angle3)\n    \n    \n# #     angle4 = tf.random.uniform(shape=[])*-45\n# #     image4 = tfa.image.rotate(image, np.pi/360*angle4)\n# #     mask4  = tfa.image.rotate(mask, np.pi/360*angle4)\n    \n    \n    \n# #     return [image1, image2, image3, image4], [mask1, mask2, mask3, mask4]\n\n#     return [image1, image2], [mask1, mask2]\n    \n# def centre_crop(image, mask):\n#     amount = tf.random.uniform(shape=[])*0.6+0.4\n#     image  = tf.image.central_crop(image, amount)\n#     mask   = tf.image.central_crop(mask, amount)\n#     return image, mask\n    \n# def resize(image, mask): \n#     image = tf.image.resize(image, img_shape[:2], method = \"lanczos3\")\n#     mask  = tf.image.resize( mask, img_shape[:2], method = \"lanczos3\") \n#     image =  (image - np.min(image)) / (np.max(image)-np.min(image))\n#     if np.max(mask)>np.min(mask):\n#         mask =  (mask - np.min(mask)) / (np.max(mask)-np.min(mask))\n#         mask = tf.cast(mask>0.5, tf.float32)\n#     else:\n#         mask = np.zeros_like(mask)\n\n#     return image, mask\n\n# def aug(image, mask, augment = True):\n#     if augment == True:\n#         image1 = image\n#         mask1 = mask\n\n#         image2 = tf.image.flip_left_right(image)\n#         mask2  = tf.image.flip_left_right(mask)\n\n#         image3 = tf.image.flip_up_down(image)\n#         mask3  = tf.image.flip_up_down(mask)\n\n#         image4 = tf.image.flip_left_right(image)\n#         mask4  = tf.image.flip_left_right(mask)\n#         image4 = tf.image.flip_up_down(image4)\n#         mask4  = tf.image.flip_up_down(mask4)\n\n#         images = [image1, image2, image3, image4]\n#         masks = [mask1, mask2, mask3, mask4]\n        \n        \n#         for i in range(4):\n#             demoimage, demomask = rotate(images[i], masks[i])\n#             images += demoimage\n#             masks += demomask\n        \n#         for i in range(len(images)):\n#             images[i] = brightness_contrast(images[i])\n#             images[i], masks[i] = centre_crop(images[i], masks[i])\n#             images[i], masks[i] = resize(images[i], masks[i])\n    \n#     images = images\n#     masks = masks\n#     return {'images':images, 'masks':masks}","metadata":{"execution":{"iopub.status.busy":"2023-10-11T04:29:15.896919Z","iopub.execute_input":"2023-10-11T04:29:15.897848Z","iopub.status.idle":"2023-10-11T04:29:15.914532Z","shell.execute_reply.started":"2023-10-11T04:29:15.897813Z","shell.execute_reply":"2023-10-11T04:29:15.910071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def get_data(path, labels_present=True, adjust_labels = False, augment = True, change_mask = False):\n#     size = len(os.listdir(os.path.join(path,\"images\")))\n    \n#     images = []\n#     if labels_present:\n#         masks = []\n\n#     for idx,i in enumerate(tqdm(os.listdir(os.path.join(path,\"images\")))):\n#         image = tf.keras.utils.load_img(os.path.join(path,\"images\",i))\n#         image = tf.keras.utils.img_to_array(image)\n#         y_nonzero, x_nonzero, _ = np.nonzero(image)\n#         image = image[np.min(y_nonzero):np.max(y_nonzero), np.min(x_nonzero):np.max(x_nonzero)]\n#         if labels_present:\n#             mask = tf.keras.utils.load_img(os.path.join(path,\"labels\",i), color_mode=\"grayscale\")\n#             mask = tf.keras.utils.img_to_array(mask)\n#             mask = mask[np.min(y_nonzero):np.max(y_nonzero), np.min(x_nonzero):np.max(x_nonzero)]\n            \n#             if change_mask==True:\n#                 mask=mask*255\n            \n#             if augment:\n#                 sample = aug(image=image, mask=mask)                    \n#                 masks+= sample['masks']\n#                 images+= sample['images']\n#             else:\n#                 image = tf.image.resize(image, img_shape[:2], method = \"lanczos3\")\n#                 mask  = tf.image.resize( mask, img_shape[:2], method = \"lanczos3\") \n#                 image =  (image - np.min(image)) / (np.max(image)-np.min(image))\n#                 if np.max(mask)>np.min(mask):\n# #                     mask =  (mask - np.min(mask)) / (np.max(mask)-np.min(mask))\n#                     mask = tf.cast(mask>0.5, tf.float32)\n#                 else:\n#                     mask = np.zeros_like(mask)\n#                 images += [image]\n#                 masks += [mask]\n                \n#         else:\n#             image = tf.image.resize(image, img_shape[:2], method = \"lanczos3\") \n#             image =  (image - np.min(image)) / (np.max(image)-np.min(image))\n#             images+=[image]\n        \n#     if labels_present:\n#         return (np.array(images),np.array(masks))\n#     else:\n#         return np.array(images)","metadata":{"execution":{"iopub.status.busy":"2023-10-11T04:29:15.920356Z","iopub.execute_input":"2023-10-11T04:29:15.922186Z","iopub.status.idle":"2023-10-11T04:29:15.934668Z","shell.execute_reply.started":"2023-10-11T04:29:15.922146Z","shell.execute_reply":"2023-10-11T04:29:15.932835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_images, train_masks = get_data(\"/kaggle/input/wounds/Foot Ulcer Segmentation Challenge/train\")\n# validation_images, validation_masks = get_data(\"/kaggle/input/wounds/Foot Ulcer Segmentation Challenge/validation\", augment = False)\n\n# test_images1 = get_data(\"/kaggle/input/wounds/Foot Ulcer Segmentation Challenge/test\", labels_present = False)\n\n# train_images, train_masks = get_data(\"/kaggle/input/wounds/Medetec_foot_ulcer_224/train\", change_mask=True)\n# validation_images, validation_masks = get_data(\"/kaggle/input/wounds/Medetec_foot_ulcer_224/test\", augment = False, change_mask=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-11T04:29:15.936245Z","iopub.execute_input":"2023-10-11T04:29:15.937794Z","iopub.status.idle":"2023-10-11T04:29:15.949263Z","shell.execute_reply.started":"2023-10-11T04:29:15.937750Z","shell.execute_reply":"2023-10-11T04:29:15.948064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_images2, train_masks2 = get_data(\"/kaggle/input/wounds/azh_wound_care_center_dataset_patches/train\")\n# validation_images2, validation_masks2 = get_data(\"/kaggle/input/wounds/azh_wound_care_center_dataset_patches/test\", augment = False)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-11T04:29:15.958458Z","iopub.execute_input":"2023-10-11T04:29:15.960623Z","iopub.status.idle":"2023-10-11T04:29:15.965644Z","shell.execute_reply.started":"2023-10-11T04:29:15.959407Z","shell.execute_reply":"2023-10-11T04:29:15.964443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_images = np.concatenate([train_images, train_images2])\n# # train_masks = np.concatenate([train_masks, train_masks2])\n\n# validation_images = np.concatenate([validation_images, validation_images2])\n# validation_masks = np.concatenate([validation_masks, validation_masks2])","metadata":{"execution":{"iopub.status.busy":"2023-10-11T04:29:15.967644Z","iopub.execute_input":"2023-10-11T04:29:15.968394Z","iopub.status.idle":"2023-10-11T04:29:15.976259Z","shell.execute_reply.started":"2023-10-11T04:29:15.968323Z","shell.execute_reply":"2023-10-11T04:29:15.975169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-10-11T04:29:15.977974Z","iopub.execute_input":"2023-10-11T04:29:15.978984Z","iopub.status.idle":"2023-10-11T04:29:16.310889Z","shell.execute_reply.started":"2023-10-11T04:29:15.978950Z","shell.execute_reply":"2023-10-11T04:29:16.309796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pth = \"WoundSegOld\"\n# os.mkdir(f\"{pth}\")\n# os.mkdir(f\"{pth}/train\")\n# os.mkdir(f\"{pth}/validation\")\n# os.mkdir(f\"{pth}/train/images\")\n# os.mkdir(f\"{pth}/train/masks\")\n# os.mkdir(f\"{pth}/validation/images\")\n# os.mkdir(f\"{pth}/validation/masks\")\n\n# for idx, i in enumerate(tqdm(np.arange(len(train_images)))):\n#     tf.keras.utils.save_img(f\"{pth}/train/images/{idx}.png\", train_images[i], scale=True, data_format=\"channels_last\")\n#     tf.keras.utils.save_img(f\"{pth}/train/masks/{idx}.png\", train_masks[i], scale=True, data_format=\"channels_last\")\n    \n\n# for idx, i in enumerate(tqdm(np.arange(len(validation_images)))):\n#     tf.keras.utils.save_img(f\"{pth}/validation/images/{idx}.png\", validation_images[i], scale=True, data_format=\"channels_last\")\n#     tf.keras.utils.save_img(f\"{pth}/validation/masks/{idx}.png\", validation_masks[i], scale=True, data_format=\"channels_last\")","metadata":{"execution":{"iopub.status.busy":"2023-10-11T04:29:16.312753Z","iopub.execute_input":"2023-10-11T04:29:16.313575Z","iopub.status.idle":"2023-10-11T04:29:16.320903Z","shell.execute_reply.started":"2023-10-11T04:29:16.313540Z","shell.execute_reply":"2023-10-11T04:29:16.319818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# idx = np.arange(len(train_images))\n# np.random.shuffle(idx)\n# train_images = train_images[idx]\n# train_masks = train_masks[idx]\n\n# idx = np.arange(len(validation_images))\n# np.random.shuffle(idx)\n# validation_images = validation_images[idx]\n# validaiton_masks = validation_masks[idx]\n\n# # del train_images1, train_images2, train_images3, train_masks1, train_masks2, train_masks3, validation_images1, validation_images2, validation_images3, validation_masks1, validation_masks2, validation_masks3\n# gc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-10-11T04:29:16.322516Z","iopub.execute_input":"2023-10-11T04:29:16.323516Z","iopub.status.idle":"2023-10-11T04:29:16.331904Z","shell.execute_reply.started":"2023-10-11T04:29:16.323481Z","shell.execute_reply":"2023-10-11T04:29:16.330736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_results(results):\n    loss,dice_coef,precision,recall,val_loss,val_dice_coef,val_precision,val_recall=results.history.values()\n    plt.figure(figsize=(20,10))\n    plt.style.use(\"ggplot\")\n\n    plt.subplot(2,2,1)\n    plt.title(\"Loss\")\n    plt.plot(loss, label=\"Training\")\n    plt.plot(val_loss, label=\"Validation\")\n    plt.legend()\n    plt.grid()\n\n    plt.subplot(2,2,2)\n    plt.title(\"Dice Coef\")\n    plt.plot(dice_coef, label=\"Training\")\n    plt.plot(val_dice_coef, label=\"Validation\")\n    plt.legend()\n    plt.grid()\n\n    plt.subplot(2,2,3)\n    plt.title(\"Precision\")\n    plt.plot(precision, label=\"Training\")\n    plt.plot(val_precision, label=\"Validation\")\n    plt.legend()\n    plt.grid()\n\n    plt.subplot(2,2,4)\n    plt.title(\"Recall\")\n    plt.plot(recall, label=\"Training\")\n    plt.plot(val_recall, label=\"Validation\")\n    plt.legend()\n    plt.grid()\n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-11T04:29:16.333258Z","iopub.execute_input":"2023-10-11T04:29:16.333662Z","iopub.status.idle":"2023-10-11T04:29:16.345239Z","shell.execute_reply.started":"2023-10-11T04:29:16.333627Z","shell.execute_reply":"2023-10-11T04:29:16.344126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoImageProcessor\ncheckpoint = \"nvidia/mit-b0\"\n# checkpoint = \"microsoft/beit-base-finetuned-ade-640-640\"\nimage_processor = AutoImageProcessor.from_pretrained(checkpoint, do_reduce_labels=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-11T04:30:16.352222Z","iopub.execute_input":"2023-10-11T04:30:16.352605Z","iopub.status.idle":"2023-10-11T04:30:16.521313Z","shell.execute_reply.started":"2023-10-11T04:30:16.352575Z","shell.execute_reply":"2023-10-11T04:30:16.520416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_image(image, title=None):\n    plt.imshow(image)\n    if title is not None:\n        plt.title(title)\n    plt.axis('off')\n\ndef show_mask(image, mask, cmap=None, alpha=0.3,title=None):\n    plt.imshow(image)\n    if title is not None:\n        plt.title(title)\n    plt.imshow(tf.squeeze(mask), cmap=cmap, alpha=alpha)\n    plt.axis('off')","metadata":{"id":"trzO5qd5sDRb","execution":{"iopub.status.busy":"2023-10-11T04:30:19.753484Z","iopub.execute_input":"2023-10-11T04:30:19.754557Z","iopub.status.idle":"2023-10-11T04:30:19.760125Z","shell.execute_reply.started":"2023-10-11T04:30:19.754527Z","shell.execute_reply":"2023-10-11T04:30:19.759203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.figure(figsize=(20,13))\n# for i in range(60):\n#     plt.subplot(5,12,i+1)\n#     id = np.random.randint(len(train_images))\n#     show_mask(train_images[i], train_masks[i], cmap='copper',alpha=0.5) # binary afmhot copper\n# #     show_image(train_images[i]) \n# plt.tight_layout()\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-11T04:30:19.910162Z","iopub.execute_input":"2023-10-11T04:30:19.910554Z","iopub.status.idle":"2023-10-11T04:30:19.915156Z","shell.execute_reply.started":"2023-10-11T04:30:19.910524Z","shell.execute_reply":"2023-10-11T04:30:19.913951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Loss Functions**","metadata":{"id":"ToSj6RQesDR_"}},{"cell_type":"code","source":"def dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = np.ravel(y_true)\n    y_pred_f = np.ravel(y_pred)\n    intersection = np.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) +smooth)\n\ndef dice_coef_loss(y_true, y_pred):\n    return 1 - dice_coef(y_true, y_pred)\n\ndef tversky(y_true, y_pred, smooth=1, alpha=0.7):\n    y_true_pos = K.flatten(y_true)\n    y_pred_pos = K.flatten(y_pred)\n    true_pos = K.sum(y_true_pos * y_pred_pos)\n    false_neg = K.sum(y_true_pos * (1 - y_pred_pos))\n    false_pos = K.sum((1 - y_true_pos) * y_pred_pos)\n    return (true_pos + smooth) / (true_pos + alpha * false_neg +(1 - alpha) * false_pos + smooth)\n\ndef tversky_loss(y_true, y_pred):\n    return 1 - tversky(y_true, y_pred)\n\n\ndef focal_tversky_loss(y_true, y_pred, gamma=0.75):\n    tv = tversky(y_true, y_pred)\n    return K.pow((1 - tv), gamma)\n\n\ndef jacard_coef(y_true, y_pred):\n    y_true_f = np.ravel(y_true)\n    y_pred_f = np.ravel(y_pred)\n    intersection = np.sum(y_true_f * y_pred_f)\n    IoU=(intersection + 1.0) / (np.sum(y_true_f) + np.sum(y_pred_f) - intersection + 1.0)\n    return IoU\n\ndef jacard_coef_loss(y_true, y_pred):\n    IoU = jacard_coef(y_true, y_pred)\n    return -IoU","metadata":{"id":"gDEVmcSFsDR_","execution":{"iopub.status.busy":"2023-10-11T04:30:20.266198Z","iopub.execute_input":"2023-10-11T04:30:20.266917Z","iopub.status.idle":"2023-10-11T04:30:20.276398Z","shell.execute_reply.started":"2023-10-11T04:30:20.266879Z","shell.execute_reply":"2023-10-11T04:30:20.275413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import evaluate\n\ndef compute_metrics(eval_pred):\n    with torch.no_grad():\n        logits, labels = eval_pred\n        logits_tensor = torch.from_numpy(logits)\n        logits_tensor = nn.functional.interpolate(\n            logits_tensor,\n            size=labels.shape[-2:],\n            mode=\"bilinear\",\n            align_corners=False,\n        ).argmax(dim=1)\n\n        pred_labels = logits_tensor.detach().cpu().numpy()\n\n        data_p = np.round(tf.keras.metrics.Precision()(labels, pred_labels),3)\n        data_r = np.round(tf.keras.metrics.Recall()(labels, pred_labels),3)\n        data_dice = np.round(dice_coef(labels, pred_labels),3)\n        data_iou = np.round(jacard_coef(labels, pred_labels),3)\n        image_p=[]\n        image_r=[]\n        image_dice=[]\n        image_iou=[]\n        for i in range(len(labels)):\n            image_p.append(tf.keras.metrics.Precision()(labels[i], pred_labels[i]))\n            image_r.append(tf.keras.metrics.Recall()(labels[i], pred_labels[i]))\n            image_dice.append(dice_coef(labels[i], pred_labels[i]))\n            image_iou.append(jacard_coef(labels[i], pred_labels[i]))\n        image_p = np.round(np.mean(image_p),2)\n        image_r = np.round(np.mean(image_r),2)\n        image_dice = np.round(np.mean(image_dice),2)\n        image_iou = np.round(np.mean(image_iou),2)\n\n\n#         model.save_pretrained(f\"{checkpoint}/{str(datetime.datetime.now())}\")\n\n        return {\"data_dice\":data_dice,\"data_iou\": data_iou , \"data_p\":data_p, \"data_r\":data_r,\n               \"image_dice\":image_dice,\"image_iou\": image_iou , \"image_p\":image_p, \"data_r\":image_r}\n\n\n\n# def compute_metrics(eval_pred):\n#     with torch.no_grad():\n#         logits, labels = eval_pred\n#         logits_tensor = torch.from_numpy(logits)\n#         logits_tensor = nn.functional.interpolate(\n#             logits_tensor,\n#             size=labels.shape[-2:],\n#             mode=\"bilinear\",\n#             align_corners=False,\n#         ).argmax(dim=1)\n\n#         pred_labels = logits_tensor.detach().cpu().numpy()\n#         metrics = metric.compute(\n#             predictions=pred_labels,\n#             references=labels,\n#             num_labels=num_labels,\n#             ignore_index=255,\n#             reduce_labels=False,\n#         )\n#         for key, value in metrics.items():\n#             if type(value) is np.ndarray:\n#                 metrics[key] = value.tolist()\n#         return metrics\n#   metrics = metric.compute(\n#         predictions=pred_labels,\n#         references=labels,\n#         num_labels=num_labels,\n#         ignore_index=0,\n#         reduce_labels=image_processor.do_reduce_labels,\n#     )\n\n#     per_category_accuracy = metrics.pop(\"per_category_accuracy\").tolist()\n#     per_category_iou = metrics.pop(\"per_category_iou\").tolist()\n\n#     metrics.update({f\"accuracy_{id2label[i]}\": v for i, v in enumerate(per_category_accuracy)})\n#     metrics.update({f\"iou_{id2label[i]}\": v for i, v in enumerate(per_category_iou)})\n    \n#     return {\"val_\" + k: v for k, v in metrics.items()}","metadata":{"execution":{"iopub.status.busy":"2023-10-11T04:30:20.675654Z","iopub.execute_input":"2023-10-11T04:30:20.675980Z","iopub.status.idle":"2023-10-11T04:30:22.000932Z","shell.execute_reply.started":"2023-10-11T04:30:20.675956Z","shell.execute_reply":"2023-10-11T04:30:21.999854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH = 16\n\n\nfrom datasets import Dataset, IterableDataset\npathx = \"/kaggle/input/wounds/FUSEGnew\"\n\n# # pathx = \"WoundSegOld\"\n# def train_series():\n#     path = f\"{pathx}/train/\"\n#     for i in os.listdir(path+\"images\"):\n#         image = tf.keras.utils.img_to_array(tf.keras.utils.load_img(path+\"images/\"+i)) \n# #         image = tf.transpose(image, (2, 0, 1))\n#         mask = tf.keras.utils.img_to_array(tf.keras.utils.load_img(path+\"masks/\"+i, color_mode=\"grayscale\"))\n#         mask = np.squeeze(mask)\n#         mask[mask==255] = 1       \n#         ans= image_processor([image],[mask])\n#         ans = {key:value[0] for key,value in ans.items()}\n#         yield ans\n# #         yield tf.convert_to_tensor(image),tf.convert_to_tensor(mask)\n\n# def validation_series():\n#     path = f\"{pathx}/validation/\"\n#     for i in os.listdir(path+\"images\"):\n#         image = tf.keras.utils.img_to_array(tf.keras.utils.load_img(path+\"images/\"+i)) \n# #         image = tf.transpose(image, (2, 0, 1))\n#         mask = tf.keras.utils.img_to_array(tf.keras.utils.load_img(path+\"masks/\"+i, color_mode=\"grayscale\")) \n#         mask = np.squeeze(mask)\n#         mask[mask==255] = 1\n        \n#         ans= image_processor([image],[mask])\n#         ans = {key:value[0] for key,value in ans.items()}\n#         yield ans\n#         yield image_processor([image],[mask])\n#         yield tf.convert_to_tensor(image),tf.convert_to_tensor(mask)\n\n# train_gen = tf.data.Dataset.from_generator(\n#     train_series, \n#     output_signature={'labels': tf.TensorSpec(shape=(512, 512), dtype=tf.int64, name=None), 'pixel_values': tf.TensorSpec(shape=(3, 512, 512), dtype=tf.float32, name=None)}\n#     ).batch(BATCH).prefetch(1)\n# # 16200\n\n# val_gen = tf.data.Dataset.from_generator(\n#     validation_series, \n#     output_signature={'labels': tf.TensorSpec(shape=(512, 512), dtype=tf.int64, name=None), 'pixel_values': tf.TensorSpec(shape=(3, 512, 512), dtype=tf.float32, name=None)}\n# ).batch(BATCH).prefetch(1)\n# #200\n\n\n\nfrom torch.utils.data import DataLoader\n# , Dataset, IterableDataset\n# class MyDataSet(IterableDataset):\n#     def __init__(self, pathx, kind):\n#         self.pathx = pathx\n#         self.kind = kind\n        \n#     def parse(self):\n#         path = f\"{self.pathx}/{self.kind}/\"\n#         for i in os.listdir(path+\"images\"):\n#             image = tf.keras.utils.img_to_array(tf.keras.utils.load_img(path+\"images/\"+i)) \n#     #         image = tf.transpose(image, (2, 0, 1))\n#             mask = tf.keras.utils.img_to_array(tf.keras.utils.load_img(path+\"masks/\"+i, color_mode=\"grayscale\")) \n#             mask = np.squeeze(mask)\n#             mask[mask==255] = 1\n\n#             ans= image_processor([image],[mask])\n#             ans = {key:value[0] for key,value in ans.items()}\n#             yield ans\n#     def get_stream(self):\n#         return cycle(self.parse())\n\n#     def __iter__(self):\n#         return self.get_strem()\n    \n#     def __len__(self):\n#         return len(os.listdir(os.path.join(self.pathx,self.kind,\"images\")))\n\n# train_gen = MyDataSet(pathx, \"train\")\n# val_gen = MyDataSet(pathx, \"validation\")\n\n\ndef parse(pathx, kind):\n        path = f\"{pathx}/{kind}/\"\n        for i in os.listdir(path+\"images\"):\n            image = tf.keras.utils.img_to_array(tf.keras.utils.load_img(path+\"images/\"+i)) \n    #         image = tf.transpose(image, (2, 0, 1))\n            mask = tf.keras.utils.img_to_array(tf.keras.utils.load_img(path+\"masks/\"+i, color_mode=\"grayscale\")) \n            mask = np.squeeze(mask)\n            mask[mask==255] = 1\n\n            ans= image_processor([image],[mask])\n            ans = {key:value[0] for key,value in ans.items()}\n            yield ans\n    \n\ntrain_gen = IterableDataset.from_generator(parse, gen_kwargs={\"pathx\":pathx, \"kind\":\"train\"})\nval_gen = IterableDataset.from_generator(parse, gen_kwargs={\"pathx\":pathx, \"kind\":\"validation\"})\n\n# train_gen = DataLoader(train_gen.with_format(\"torch\"), num_workers=2) \n# val_gen = DataLoader(val_gen.with_format(\"torch\"), num_workers=2)  \n\ntrain_gen = train_gen.with_format(\"torch\")\nval_gen = val_gen.with_format(\"torch\")","metadata":{"execution":{"iopub.status.busy":"2023-10-11T04:30:22.003207Z","iopub.execute_input":"2023-10-11T04:30:22.003991Z","iopub.status.idle":"2023-10-11T04:30:22.033848Z","shell.execute_reply.started":"2023-10-11T04:30:22.003958Z","shell.execute_reply":"2023-10-11T04:30:22.032675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Training**","metadata":{"id":"nRQpDad5sDSB"}},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-10-11T04:30:22.035576Z","iopub.execute_input":"2023-10-11T04:30:22.036152Z","iopub.status.idle":"2023-10-11T04:30:22.367690Z","shell.execute_reply.started":"2023-10-11T04:30:22.036119Z","shell.execute_reply":"2023-10-11T04:30:22.366616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSemanticSegmentation, TrainingArguments, Trainer\nfrom transformers import BeitForSemanticSegmentation\nmodel = AutoModelForSemanticSegmentation.from_pretrained(checkpoint, id2label=id2label, label2id=label2id, ignore_mismatched_sizes=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-11T04:30:39.150956Z","iopub.execute_input":"2023-10-11T04:30:39.151293Z","iopub.status.idle":"2023-10-11T04:30:39.310277Z","shell.execute_reply.started":"2023-10-11T04:30:39.151267Z","shell.execute_reply":"2023-10-11T04:30:39.309409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def print_trainable_parameters(model):\n    \"\"\"\n    Prints the number of trainable parameters in the model.\n    \"\"\"\n    trainable_params = 0\n    all_param = 0\n    for _, param in model.named_parameters():\n        all_param += param.numel()\n        if param.requires_grad:\n            trainable_params += param.numel()\n    print(\n        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}\"\n    )","metadata":{"execution":{"iopub.status.busy":"2023-10-11T04:30:41.383136Z","iopub.execute_input":"2023-10-11T04:30:41.383522Z","iopub.status.idle":"2023-10-11T04:30:41.389719Z","shell.execute_reply.started":"2023-10-11T04:30:41.383494Z","shell.execute_reply":"2023-10-11T04:30:41.388393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\npeft_config = LoraConfig(target_modules=[\"query\",\"key\",\"value\"], inference_mode=False, r=8, lora_alpha=8, lora_dropout=0.1, bias=\"all\")\n\nmodel = get_peft_model(model, peft_config)\n\nprint_trainable_parameters(model)","metadata":{"execution":{"iopub.status.busy":"2023-10-11T04:30:41.627305Z","iopub.execute_input":"2023-10-11T04:30:41.628048Z","iopub.status.idle":"2023-10-11T04:30:41.673552Z","shell.execute_reply.started":"2023-10-11T04:30:41.628016Z","shell.execute_reply":"2023-10-11T04:30:41.672436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    report_to=\"none\",\n    output_dir=\"segformer-b0-scene-parse-150\",\n    learning_rate=6e-5,\n    num_train_epochs=10,\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    \n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    save_total_limit=3,\n    remove_unused_columns=False,\n    max_steps = len(os.listdir(os.path.join(pathx,\"train\",\"images\"))),\n    label_names=[\"labels\"],\n    fp16 = True\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_gen,\n    eval_dataset=val_gen,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()\n\ngc.collect()","metadata":{"id":"-jx1-05usDSB","outputId":"b3cdba4f-54b5-424d-fd4b-8859065c5776","execution":{"iopub.status.busy":"2023-10-11T04:30:43.796211Z","iopub.execute_input":"2023-10-11T04:30:43.796903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(model.count_params())\nnp.sum([np.prod(v.get_shape().as_list()) for v in model.trainable_variables])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_pretrained(\"BestSegFormer\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !zip -r -q MODEL.zip BestModel.h5\n# from IPython.display import FileLink\n# FileLink(r'MODEL.zip')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2 = sm.FPN(backbone_name=backbones[7],input_shape=img_shape, classes=1, activation='sigmoid')\n\n# l2 = tf.keras.regularizers.l2(1e-5)\n# for layer in model.layers:\n#     if hasattr(layer, 'kernel'):\n# #     if isinstance(layer, tf.keras.layers.Conv2D):\n#         model.add_loss(lambda layer=layer: l2(layer.kernel))\n\n\n\n# Compile\nmodel2.compile(\n    loss=dice_coef_loss,\n    optimizer=tf.optimizers.Adam(learning_rate=0.00001),\n    metrics=[dice_coef,tf.keras.metrics.Precision(),tf.keras.metrics.Recall()],\n)\n\nmodel2.load_weights(\"BestModel.h5\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2.evaluate(eval_gen)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"demo = model.predict(train_images[:10])\n\nplt.figure(figsize=(20,13))\nfor i in range(10):\n    plt.subplot(5,8,i+1)\n    id = np.random.randint(len(train_images))\n    show_mask(train_images[i], demo[i]>0.5, cmap='binary',alpha=0.5) # binary afmhot copper\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_weights(\"Segmentation.h5\")","metadata":{"id":"wvXLtitUsDSC","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Evaluation**","metadata":{"id":"F7bnQhu4sDSC"}},{"cell_type":"code","source":"# loss,segmentation_loss,prediction_loss,segmentation_accuracy,segmentation_IoU,prediction_accuracy,\\\n# val_loss,val_segmentation_loss,val_prediction_loss,val_segmentation_accuracy,val_segmentation_IoU,val_prediction_accuracy=\n","metadata":{"id":"LYBpdKxPsDSE","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(18,12))\nn=0\nfor i in range(1,(4*6)+1):\n    plt.subplot(4,6,i)\n    if n==0:\n        id = np.random.randint(len(images))\n        image = images[id]\n        mask = masks[id]\n        pred_mask = model.predict(image[np.newaxis,...])\n        show_mask(image, mask,title=\"Original Mask: \"+labels_name[np.argmax(labels[id])],alpha=0.6, cmap='copper')\n        n+=1\n    elif n==1:\n        show_mask(image, tf.cast(pred_mask>0.5,tf.float32), title=\"Predicted Mask:\",alpha=0.6,cmap='copper')\n        n+=1\n\n    elif n==2:\n        id = np.random.randint(len(images))\n        image = images[id]\n        mask = masks[id]\n        pred_mask = model.predict(image[np.newaxis,...])\n        show_mask(image, mask,title=\"Original Mask: \"+labels_name[np.argmax(labels[id])],alpha=0.6, cmap='copper')\n        n+=1\n    elif n==3:\n        show_mask(image, tf.cast(pred_mask>0.5,tf.float32), title=\"Predicted Mask:\",alpha=0.6,cmap='copper')\n        n+=1\n\n    elif n==4:\n        id = np.random.randint(len(images))\n        image = images[id]\n        mask = masks[id]\n        pred_mask = model.predict(image[np.newaxis,...])\n        show_mask(image, mask,title=\"Original Mask: \"+labels_name[np.argmax(labels[id])],alpha=0.6, cmap='copper')\n        n+=1\n    else:\n        show_mask(image, tf.cast(pred_mask>0.5,tf.float32), title=\"Predicted Mask:\",alpha=0.6,cmap='copper')\n        n=0\n\nplt.tight_layout()\nplt.show()","metadata":{"id":"PVN0Z7S4sDSF","outputId":"3f8b49b2-a64a-4122-9265-be610ed43ecf","trusted":true},"execution_count":null,"outputs":[]}]}